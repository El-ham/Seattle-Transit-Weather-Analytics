{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e9d90c8b-8391-435d-b5b0-6f17e7c87dbd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 97 - Data Validation Tests: Ensuring Data Quality Across Layers\n",
    "\n",
    "**Purpose**  \n",
    "This notebook validates the integrity and quality of key datasets in the Silver and Gold layers before analytics or ML modeling.\n",
    "\n",
    "### ‚úÖ Tests Included\n",
    "- **Missing values**: No nulls in critical columns like `event_ts`, `temperature`, `vehicle_id`\n",
    "- **Reasonable ranges**:\n",
    "  - Temperature between -50¬∞F and 150¬∞F\n",
    "  - Latitude/longitude within Seattle bounds\n",
    "- **Primary key uniqueness**:\n",
    "  - No duplicate `(vehicle_id, event_ts)` in GTFS-RT\n",
    "- **Optional**: Temporal logic (e.g., `forecast_time ‚â• event_ts`)\n",
    "\n",
    "Each test displays PASS/FAIL status and row counts for invalid records, supporting early anomaly detection before downstream tasks.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6d619f2f-d464-47fd-9b92-8674bbfc9a5c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Data Quality & Validation Layer for Seattle Transit & Weather Project\n",
    "from pyspark.sql import functions as F\n",
    "import datetime as dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e46eaf08-843c-43aa-9323-6041f1ce8018",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "stakeholders_text = \"\"\n",
    "# Get today's date for reporting\n",
    "REPORT_DATE = dt.date.today().isoformat()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "880db0fc-f751-4898-98c9-57ca7f62f760",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# ‚úÖ Load Silver and Gold Delta Tables\n",
    "df_rt = spark.read.format(\"delta\").load(\"dbfs:/silver/gtfs_rt\")\n",
    "df_weather = spark.read.format(\"delta\").load(\"dbfs:/silver/weather\")\n",
    "df_stops = spark.read.format(\"delta\").load(\"dbfs:/silver/gtfs_static/2025-05-21/stops\")\n",
    "df_gold = spark.read.format(\"delta\").load(\"dbfs:/gold/gtfs_rt_weather_joined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8e7cc62e-1aad-46d6-ab5b-35c94d051a82",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Test 1: Null Checks\n",
    "\n",
    "print(\"\\nüîç Test 1: Nulls in Critical Columns\")\n",
    "\n",
    "flag_event_ts = flag_vehicle_id = flag_temp = flag_forecast_time = 0\n",
    "\n",
    "null_event_ts = df_rt.filter(F.col(\"event_ts\").isNull())\n",
    "count_event_ts = null_event_ts.count()\n",
    "if count_event_ts > 0:\n",
    "    flag_event_ts = 1\n",
    "    print(f\"Null event_ts in GTFS RT: {count_event_ts}\")\n",
    "    stakeholders_text += f\"Null event_ts in GTFS RT: {count_event_ts}\\nSample rows:\\n{null_event_ts.limit(5).toPandas().to_string(index=False)}\\n\\n\"\n",
    "\n",
    "null_vehicle_id = df_rt.filter(F.col(\"vehicle_id\").isNull())\n",
    "count_vehicle_id = null_vehicle_id.count()\n",
    "if count_vehicle_id > 0:\n",
    "    flag_vehicle_id = 1\n",
    "    print(f\"Null vehicle_id in GTFS RT: {count_vehicle_id}\")\n",
    "    stakeholders_text += f\"Null vehicle_id in GTFS RT: {count_vehicle_id}\\nSample rows:\\n{null_vehicle_id.limit(5).toPandas().to_string(index=False)}\\n\\n\"\n",
    "\n",
    "null_temp = df_weather.filter(F.col(\"temperature\").isNull())\n",
    "count_temp = null_temp.count()\n",
    "if count_temp > 0:\n",
    "    flag_temp = 1\n",
    "    print(f\"Null temperature in Weather: {count_temp}\")\n",
    "    stakeholders_text += f\"Null temperature in Weather: {count_temp}\\nSample rows:\\n{null_temp.limit(5).toPandas().to_string(index=False)}\\n\\n\"\n",
    "\n",
    "null_forecast_time = df_weather.filter(F.col(\"forecast_time\").isNull())\n",
    "count_forecast_time = null_forecast_time.count()\n",
    "if count_forecast_time > 0:\n",
    "    flag_forecast_time = 1\n",
    "    print(f\"Null forecast_time in Weather: {count_forecast_time}\")\n",
    "    stakeholders_text += f\"Null forecast_time in Weather: {count_forecast_time}\\nSample rows:\\n{null_forecast_time.limit(5).toPandas().to_string(index=False)}\\n\\n\"\n",
    "\n",
    "if not any([flag_event_ts, flag_vehicle_id, flag_temp, flag_forecast_time]):\n",
    "    print(\"‚úÖ PASS: No nulls found in critical columns.\")\n",
    "else:\n",
    "    print(\"\\nüîî Issues found ‚Äî see stakeholders_text summary below.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e10c6986-aa4b-4081-8b51-43b01f036f93",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(\"\\nüîç Test 2: Value Ranges\")\n",
    "\n",
    "flag_temp_range = flag_rt_coords = flag_static_coords = 0\n",
    "\n",
    "# Temperature outliers\n",
    "temp_outliers_df = df_weather.filter((F.col(\"temperature\") < -50) | (F.col(\"temperature\") > 150))\n",
    "count_temp_outliers = temp_outliers_df.count()\n",
    "if count_temp_outliers > 0:\n",
    "    flag_temp_range = 1\n",
    "    print(f\"Unrealistic temperatures: {count_temp_outliers}\")\n",
    "    stakeholders_text += f\"Unrealistic temperatures: {count_temp_outliers}\\nSample rows:\\n{temp_outliers_df.limit(5).toPandas().to_string(index=False)}\\n\\n\"\n",
    "\n",
    "# GTFS-RT lat/lon out of Seattle bounds\n",
    "rt_coord_outliers_df = df_rt.filter((F.col(\"latitude\") < 47) | (F.col(\"latitude\") > 48) |\n",
    "                                    (F.col(\"longitude\") < -123) | (F.col(\"longitude\") > -121))\n",
    "count_rt_coord_outliers = rt_coord_outliers_df.count()\n",
    "if count_rt_coord_outliers > 0:\n",
    "    flag_rt_coords = 1\n",
    "    print(f\"GTFS RT records outside Seattle bounds: {count_rt_coord_outliers}\")\n",
    "    stakeholders_text += f\"GTFS RT records outside Seattle bounds: {count_rt_coord_outliers}\\nSample rows:\\n{rt_coord_outliers_df.limit(5).toPandas().to_string(index=False)}\\n\\n\"\n",
    "\n",
    "# Static stops out of range\n",
    "stop_coord_outliers_df = df_stops.filter(~((F.col(\"location.stop_lat\").between(47.1, 47.9)) &\n",
    "                                           (F.col(\"location.stop_lon\").between(-122.6, -121.5))))\n",
    "count_static_coord_outliers = stop_coord_outliers_df.count()\n",
    "if count_static_coord_outliers > 0:\n",
    "    flag_static_coords = 1\n",
    "    print(f\"Static stops with out-of-range lat/lon: {count_static_coord_outliers}\")\n",
    "    stakeholders_text += f\"Static stops with out-of-range lat/lon: {count_static_coord_outliers}\\nSample rows:\\n{stop_coord_outliers_df.limit(5).toPandas().to_string(index=False)}\\n\\n\"\n",
    "\n",
    "if not any([flag_temp_range, flag_rt_coords, flag_static_coords]):\n",
    "    print(\"‚úÖ PASS: All values fall within expected geographic and temperature ranges.\")\n",
    "else:\n",
    "    print(\"\\nüîî Issues found ‚Äî see stakeholders_text summary below.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c00d9858-8381-471a-a1d2-a6ea2d343be1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(\"\\nüîç Test 3: Duplicate Primary Keys\")\n",
    "\n",
    "flag_duplicates = 0\n",
    "\n",
    "duplicates_rt_df = (\n",
    "    df_rt.groupBy(\"vehicle_id\", \"event_ts\")\n",
    "    .count()\n",
    "    .filter(\"count > 1\")\n",
    "    .orderBy(F.desc(\"count\"))\n",
    ")\n",
    "\n",
    "count_duplicates = duplicates_rt_df.count()\n",
    "\n",
    "if count_duplicates > 0:\n",
    "    flag_duplicates = 1\n",
    "    print(f\"Duplicate vehicle_id + event_ts in GTFS RT: {count_duplicates}\")\n",
    "    stakeholders_text += (\n",
    "        f\"Duplicate GTFS RT records by vehicle_id + event_ts: {count_duplicates}\\n\"\n",
    "        + \"Sample rows:\\n\"\n",
    "        + duplicates_rt_df.limit(5).toPandas().to_string(index=False)\n",
    "        + \"\\n\\n\"\n",
    "    )\n",
    "else:\n",
    "    print(\"‚úÖ PASS: No duplicate primary key records found in GTFS RT.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5577cadf-2d57-4e60-8086-934020948c44",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "duplicates_rt_df.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "591841d6-cd72-49a4-ac33-4dbc4cc37b23",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(\"\\nüîç Test 4: forecast_time Before event_ts\")\n",
    "\n",
    "flag_invalid_order = 0\n",
    "\n",
    "invalid_order_df = df_gold.filter(F.col(\"forecast_time\") < F.col(\"event_ts\"))\n",
    "invalid_order_count = invalid_order_df.count()\n",
    "\n",
    "if invalid_order_count > 0:\n",
    "    flag_invalid_order = 1\n",
    "    print(f\"Gold rows with forecast_time before event_ts: {invalid_order_count}\")\n",
    "    stakeholders_text += (\n",
    "        f\"Gold rows with forecast_time before event_ts: {invalid_order_count}\\n\"\n",
    "        + \"Sample rows:\\n\"\n",
    "        + invalid_order_df.select(\"vehicle_id\", \"event_ts\", \"forecast_time\")\n",
    "            .limit(5)\n",
    "            .toPandas()\n",
    "            .to_string(index=False)\n",
    "        + \"\\n\\n\"\n",
    "    )\n",
    "else:\n",
    "    print(\"‚úÖ PASS: All gold records have forecast_time after or equal to event_ts.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b2f5e54c-dedb-45b5-ae03-9aca4d328f60",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "if stakeholders_text != \"\":\n",
    "    final_text = f\"\"\"\n",
    "    Dear Stakeholders:\n",
    "    Data quality issues found on {REPORT_DATE}:\n",
    "    \"\"\" + stakeholders_text + \"\"\"\n",
    "    Please review the samples and address the above issues before proceeding with analytics or modeling.\n",
    "    Best regards,\n",
    "    Data Engineering Team\n",
    "    \"\"\"\n",
    "else:\n",
    "    final_text = f\"\"\"\n",
    "    Dear Stakeholders:\n",
    "    No data quality issues found on {REPORT_DATE}.\n",
    "    The datasets passed all validation checks.\n",
    "    Best regards,\n",
    "    Data Engineering Team\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cf8cf553-0aff-4f62-86b9-f753018a5e87",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(final_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7c5dcd31-6405-40ce-a998-d0fcc946fd56",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "97_data_validation_tests",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
