{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "50ee9bf1-1d7a-40a2-8510-683c222fc656",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 02 - Ingest GTFS Real-Time Data (Bronze Layer)\n",
    "\n",
    "Ingests real-time vehicle position data from King County Metro into the Bronze Delta Lake layer.\n",
    "\n",
    "\n",
    "### Purpose\n",
    "Capture daily transit activity (vehicle location and metadata) for use in downstream analysis and weather correlation.\n",
    "\n",
    "\n",
    "### Steps\n",
    "- Fetches GTFS-RT feed (Protobuf format)  \n",
    "- Extracts fields: `vehicle_id`, `route_id`, `trip_id`, `latitude`, `longitude`, `timestamp`  \n",
    "- Adds `ingestion_date` for partitioning  \n",
    "- Writes to Delta table: `dbfs:/bronze/gtfs_rt/`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e74c3b43-d73d-4047-8aa1-ae0027236697",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# dbutils.fs.rm(\"dbfs:/bronze/gtfs_rt/\", recurse=True)     One-time utility: This cell is only needed the very first time you switch from overwrite to append logic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ba28c086-93be-429f-8d7e-5c273ac6217f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%pip install gtfs-realtime-bindings --quiet\n",
    "dbutils.library.restartPython()\n",
    "# ⚠️ Only needed once per cluster restart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6fb74d52-2cf7-46ec-a59a-c44010237433",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "from google.transit import gtfs_realtime_pb2\n",
    "import requests\n",
    "\n",
    "# Use today's date dynamically\n",
    "INGESTION_DATE = dt.date.today().isoformat()\n",
    "\n",
    "# Bronze layer path (partitioned by ingestion_date)\n",
    "BRONZE_RT_PATH = \"dbfs:/bronze/gtfs_rt/\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7b67a7fc-fea1-45f7-ac00-53c5a0932bf1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "URL = \"https://s3.amazonaws.com/kcm-alerts-realtime-prod/vehiclepositions.pb\"\n",
    "response = requests.get(URL)\n",
    "# Parse GTFS-RT feed\n",
    "feed = gtfs_realtime_pb2.FeedMessage()\n",
    "feed.ParseFromString(response.content)\n",
    "\n",
    "print(f\"# of entities: {len(feed.entity)}\")\n",
    "print(feed.entity[0]) if feed.entity else print('No vehicle updates available.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b53600a3-977d-4fbe-9b05-56aa5f1cbbb3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType, StructField, StringType, DoubleType, LongType, TimestampType\n",
    "from pyspark.sql.functions import lit\n",
    "from datetime import datetime\n",
    "\n",
    "# Define schema for structured data\n",
    "schema = StructType([\n",
    "    StructField(\"vehicle_id\", StringType(), True),\n",
    "    StructField(\"trip_id\", StringType(), True),\n",
    "    StructField(\"route_id\", StringType(), True),\n",
    "    StructField(\"latitude\", DoubleType(), True),\n",
    "    StructField(\"longitude\", DoubleType(), True),\n",
    "    StructField(\"timestamp\", LongType(), True),\n",
    "    StructField(\"ingestion_ts\", TimestampType(), True)\n",
    "])\n",
    "\n",
    "# Parse rows from feed\n",
    "rows = []\n",
    "\n",
    "if feed.entity:\n",
    "    for entity in feed.entity:\n",
    "        vehicle = entity.vehicle\n",
    "        position = vehicle.position\n",
    "        trip = vehicle.trip\n",
    "\n",
    "        rows.append((\n",
    "            entity.id,\n",
    "            trip.trip_id,\n",
    "            trip.route_id,\n",
    "            position.latitude,\n",
    "            position.longitude,\n",
    "            vehicle.timestamp,\n",
    "            datetime.utcnow()\n",
    "        ))\n",
    "else:\n",
    "    print(\"No vehicle updates available. Creating an empty DataFrame.\")\n",
    "\n",
    "# Create Spark DataFrame\n",
    "df_rt = spark.createDataFrame(rows, schema)\n",
    "\n",
    "# Add ingestion_date for partitioning\n",
    "df_rt = df_rt.withColumn(\"ingestion_date\", lit(INGESTION_DATE))\n",
    "\n",
    "# Filter out rows with invalid timestamp\n",
    "df_rt = df_rt.filter(\"timestamp > 0\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fc6ef66b-95f7-47bf-9307-3654a5892a6c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# 🆕 Step: Remove duplicates using anti-join based on vehicle_id and timestamp\n",
    "try:\n",
    "    existing_df = spark.read.format(\"delta\").load(BRONZE_RT_PATH).select(\"vehicle_id\", \"timestamp\")\n",
    "    df_rt = df_rt.alias(\"new\").join(\n",
    "        existing_df.alias(\"existing\"),\n",
    "        on=[\"vehicle_id\", \"timestamp\"],\n",
    "        how=\"left_anti\"\n",
    "    )\n",
    "except Exception as e:\n",
    "    print(f\"✓ No existing data found or table is empty. Proceeding without anti-join. Error: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1a04ce15-1844-4cf2-8815-9d9b4de7efd4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Write to Delta (append mode with daily partition)\n",
    "df_rt.write \\\n",
    "    .format(\"delta\") \\\n",
    "    .mode(\"append\") \\\n",
    "    .partitionBy(\"ingestion_date\") \\\n",
    "    .save(BRONZE_RT_PATH)\n",
    "\n",
    "print(\"✓ GTFS-RT Bronze ingest appended to Delta without duplicates\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5c05c96b-7d45-4066-8360-0e0a82ea54cb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_check = spark.read.format(\"delta\").load(BRONZE_RT_PATH)\n",
    "df_check.filter(f\"ingestion_date = '{INGESTION_DATE}'\").show(5, truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "07bcbf6d-3393-4470-9697-d7797156dab8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "02_ingest_gtfs_rt",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
