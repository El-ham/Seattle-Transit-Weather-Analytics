{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d5ef3ea2-ce89-4318-a6a7-a221402b86cd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 04 - Enrich GTFS Real-Time with Static Data (Gold Layer)\n",
    "\n",
    "This notebook joins real-time GTFS vehicle updates with static route/trip metadata from King County Metro to create an enriched, analysis-ready dataset in the Gold layer.\n",
    "\n",
    "### Purpose\n",
    "To enhance real-time transit records by associating each update with its corresponding route type, direction, and short name — enabling more insightful downstream analysis.\n",
    "\n",
    "### Workflow Summary\n",
    "- Loads real-time GTFS updates from the Silver layer (today’s data only)\n",
    "- Loads static `trips` and `routes` tables from the GTFS static feed\n",
    "- Joins real-time updates with static trip and route metadata\n",
    "- Appends the enriched data to the partitioned Gold Delta table\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4a970b4e-0339-4a60-9bdd-813c43ca2f4c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# dbutils.fs.rm(\"dbfs:/gold/gtfs_rt_enriched/\", recurse=True)       One-time utility: This cell is only needed the very first time you switch from overwrite to append logic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b1be6fe2-df63-4ea9-8b29-002b52de63d1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "\n",
    "# Use today’s date for ingesting real-time data\n",
    "INGESTION_DATE = dt.date.today().isoformat()\n",
    "\n",
    "# Keep static GTFS date constant (doesn’t change daily)\n",
    "STATIC_DATE = \"2025-05-21\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6c6b8f3c-ff43-4031-801f-7f3a7e8ac104",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "\n",
    "# Define Silver-layer input path (real-time)\n",
    "RT_SILVER_PATH = \"dbfs:/silver/gtfs_rt/\"\n",
    "\n",
    "# Define static GTFS paths for trips and routes from the given snapshot date\n",
    "TRIPS_SILVER_PATH  = f\"dbfs:/silver/gtfs_static/trips\"\n",
    "ROUTES_SILVER_PATH = f\"dbfs:/silver/gtfs_static/routes\"\n",
    "\n",
    "# Target path for writing enriched Gold-layer data\n",
    "GOLD_PATH = \"dbfs:/gold/gtfs_rt_enriched/\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "16654390-21c4-4f3d-9e9c-042cd77c12fb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Load real-time Silver-layer data for today\n",
    "# Filter out rows without trip_id or missing location data\n",
    "df_rt = (\n",
    "    spark.read.format(\"delta\").load(RT_SILVER_PATH)\n",
    "    .filter(F.col(\"ingestion_date\") == INGESTION_DATE)\n",
    "    .filter(F.col(\"trip_id\").isNotNull())  # ✅ Required for joining\n",
    "    .filter(F.col(\"latitude\").isNotNull() & F.col(\"longitude\").isNotNull())  # ✅ Required for location\n",
    ")\n",
    "\n",
    "# Load static trip and route metadata\n",
    "df_trips  = spark.read.format(\"delta\").load(TRIPS_SILVER_PATH)\n",
    "df_routes = spark.read.format(\"delta\").load(ROUTES_SILVER_PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "efeea07b-1682-42d5-87d4-833d513503ee",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Drop existing route_id from real-time data to avoid duplication in join\n",
    "df_rt_clean = df_rt.drop(\"route_id\")  # prevents duplicate later\n",
    "\n",
    "# Join real-time updates with trips to get route_id and direction_id\n",
    "df_joined = (\n",
    "    df_rt_clean\n",
    "    .join(df_trips.select(\"trip_id\", \"route_id\", \"direction_id\"), on=\"trip_id\", how=\"left\")\n",
    ")\n",
    "\n",
    "# Further join with routes to get route type and short name\n",
    "df_enriched = (\n",
    "    df_joined\n",
    "    .join(\n",
    "        df_routes.select(\"route_id\", \"route_short_name\", \"route_type\"),\n",
    "        on=\"route_id\",\n",
    "        how=\"left\"\n",
    "    )\n",
    "    .withColumn(\"joined_at\", F.current_timestamp())\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "984006f6-9f17-42e3-9db1-d183cd1f80cd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Sanity check: how many records are missing route metadata after joining?\n",
    "df_enriched.filter(F.col(\"route_id\").isNull() | F.col(\"route_short_name\").isNull()).count()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ef05a036-c3be-4a0f-a621-537e2ac9c0a4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Preview enriched result with key fields\n",
    "df_enriched.select(\n",
    "    \"vehicle_id\", \"route_short_name\", \"direction_id\", \n",
    "    \"latitude\", \"longitude\", \"event_ts\", \"joined_at\"\n",
    ").show(5, truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b5578d8a-209f-424c-bb4c-9434cd293905",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Add ingestion date partition column before writing to Gold layer\n",
    "df_enriched = df_enriched.withColumn(\"ingestion_date\", F.lit(INGESTION_DATE))\n",
    "\n",
    "# Deduplicate before writing to Gold\n",
    "try:\n",
    "    existing_gold = spark.read.format(\"delta\").load(GOLD_PATH).select(\"vehicle_id\", \"event_ts\")\n",
    "    \n",
    "    df_enriched = df_enriched.alias(\"new\").join(\n",
    "        existing_gold.alias(\"existing\"),\n",
    "        on=[\"vehicle_id\", \"event_ts\"],\n",
    "        how=\"left_anti\"\n",
    "    )\n",
    "except Exception as e:\n",
    "    print(f\"✓ No existing Gold data found or table is empty. Proceeding without anti-join. Error: {e}\")\n",
    "\n",
    "# Append enriched data to Gold Delta table\n",
    "df_enriched.write \\\n",
    "    .format(\"delta\") \\\n",
    "    .mode(\"append\") \\\n",
    "    .partitionBy(\"ingestion_date\") \\\n",
    "    .save(GOLD_PATH)\n",
    "\n",
    "print(\"✓ GTFS-RT Enriched data appended to Gold\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "95025e84-0e40-4727-8d28-0df84d2f25fb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Print column names to confirm schema\n",
    "print(df_enriched.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0b73c47f-0dc1-4642-87e4-ca34f53a0ca6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "04_enrich_rt_with_static",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
